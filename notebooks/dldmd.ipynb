{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85c6b0d",
   "metadata": {},
   "source": [
    "# Deep-Learning enhanced Dynamic Mode Decomposition\n",
    "In this notebook we're going to reproduce the DMD presented in [1].\n",
    "\n",
    "## Model architecture\n",
    "1. MLP: Encode the input\n",
    "2. DMD: Apply the DMD algorithm\n",
    "3. MLP: Decode the DMD output\n",
    "\n",
    "The idea is to pair DMD with an autoencoder whose job is to find an optimal encoding to improve DMD accuracy (both in reconstruction and accuracy). More insights in [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90b5f6",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "First of all we import a few modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcde5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import logging\n",
    "from functools import wraps\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Sequential, ReLU, Linear, Module\n",
    "\n",
    "from pydmd import DMD\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694a4e2",
   "metadata": {},
   "source": [
    "We prepare a special decorator `@timer` which decorates function for which we'd like to know the execution time. We're going to use this in the `DLDMD` class further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf2797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    @wraps(func)\n",
    "    def timed_func(*args, **kwargs):\n",
    "        start = time.time_ns()\n",
    "        val = func(*args, **kwargs)\n",
    "        dt_ms = (time.time_ns() - start) / 1_000_000\n",
    "        return dt_ms, val\n",
    "\n",
    "    return timed_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3bb225",
   "metadata": {},
   "source": [
    "Finally we define the `DLDMD` class (obvisouly extending `torch.nn.Module`). The compulsory parameters are:\n",
    "+ The encoder module;\n",
    "+ A DMD instance from PyDMD\n",
    "+ The decoder module;\n",
    "\n",
    "In addition, the user may provide:\n",
    "+ 4 training weights for the different outputs given by DMD (reconstruction, prediction, phase space, encoding accuracy);\n",
    "+ An optimizer (by default we use `Adam`);\n",
    "+ A `dict` of optimizer parameters;\n",
    "+ The number of snapshots to be predicted (and therefore to train upon).\n",
    "\n",
    "`DLDMD` provides methods for the forward pass (`forward`) which specializes in `train_step` and `eval_step`. It handles the computation of the loss function, and model-saving as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e66fc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLDMD(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        dmd,\n",
    "        decoder,\n",
    "        encoding_weight,\n",
    "        reconstruction_weight,\n",
    "        prediction_weight,\n",
    "        phase_space_weight,\n",
    "        optimizer=optim.Adam,\n",
    "        optimizer_kwargs={\"lr\": 1.0e-3, \"weight_decay\": 1.0e-9},\n",
    "        n_prediction_snapshots=1,\n",
    "        eval_on_cpu=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._encoder = encoder\n",
    "        self._decoder = decoder\n",
    "        \n",
    "        self._optimizer = optimizer(self.parameters(), **optimizer_kwargs)\n",
    "        logger.info(f\"Optimizer: {self._optimizer}\")\n",
    "\n",
    "        self._encoding_weight = encoding_weight\n",
    "        self._reconstruction_weight = reconstruction_weight\n",
    "        self._prediction_weight = prediction_weight\n",
    "        self._phase_space_weight = phase_space_weight\n",
    "\n",
    "        self._eval_on_cpu = eval_on_cpu\n",
    "\n",
    "        logger.info(f\"DMD instance: {type(dmd)}\")\n",
    "        self._dmd = dmd\n",
    "        # a copy of dmd to be used only for evaluation\n",
    "        self._eval_dmd = deepcopy(dmd)\n",
    "\n",
    "        self._n_prediction_snapshots = n_prediction_snapshots\n",
    "        logger.info(\n",
    "            f\"DMD will predict {n_prediction_snapshots} snapshots during training.\"\n",
    "        )\n",
    "\n",
    "        logger.info(\"----- DLDMD children -----\")\n",
    "        logger.info(tuple(self.children()))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.ndim == 2:\n",
    "            input = input[None]\n",
    "\n",
    "        logger.debug(f\"Input shape: {input.shape}\")\n",
    "        encoded_input = self._encoder(input.swapaxes(-1, -2))\n",
    "        logger.debug(f\"Encoded input shape: {encoded_input.shape}\")\n",
    "        self._dmd.fit(encoded_input.swapaxes(-1, -2), batch=True)\n",
    "        self._dmd.dmd_time[\"tend\"] = (\n",
    "            self._dmd.original_time[\"tend\"] + self._n_prediction_snapshots\n",
    "        )\n",
    "\n",
    "        encoded_output = self._dmd.reconstructed_data.swapaxes(-1, -2)\n",
    "        logger.debug(f\"Encoded output shape: {encoded_output.shape}\")\n",
    "\n",
    "        if not torch.is_complex(input):\n",
    "            old_dtype = encoded_output.dtype\n",
    "            encoded_output = encoded_output.real\n",
    "            logger.debug(\n",
    "                f\"Removing complex part from output_immersion: {old_dtype} to {encoded_output.dtype}\"\n",
    "            )\n",
    "        if encoded_output.dtype != input.dtype:\n",
    "            logger.debug(\n",
    "                f\"Casting output_immersion dtype from {encoded_output.dtype} to {input.dtype}\"\n",
    "            )\n",
    "            encoded_output = encoded_output.to(dtype=input.dtype)\n",
    "\n",
    "        return self._decoder(encoded_output).swapaxes(-1, -2)\n",
    "\n",
    "    def _dmd_training_snapshots(self, snapshots):\n",
    "        if self._n_prediction_snapshots > 0:\n",
    "            return snapshots[..., :, : -self._n_prediction_snapshots]\n",
    "        return snapshots\n",
    "\n",
    "    def _prediction_snapshots(self, snapshots):\n",
    "        if self._n_prediction_snapshots > 0:\n",
    "            return snapshots[..., :, -self._n_prediction_snapshots :]\n",
    "        return torch.zeros(0)\n",
    "\n",
    "    def _compute_loss(self, output, input):\n",
    "        logger.debug(f\"Input shape: {input.shape}\")\n",
    "        logger.debug(f\"Output shape: {output.shape}\")\n",
    "\n",
    "        decoder_loss = mse_loss(self._decoder(self._encoder(input.swapaxes(-1,-2))).swapaxes(-1,-2), input)\n",
    "\n",
    "        batched_psp = self._dmd.operator.phase_space_prediction\n",
    "        psp_loss = torch.linalg.matrix_norm(batched_psp).sum()\n",
    "\n",
    "        reconstruction_loss = mse_loss(\n",
    "            self._dmd_training_snapshots(output),\n",
    "            self._dmd_training_snapshots(input),\n",
    "        )\n",
    "\n",
    "        prediction_loss = mse_loss(\n",
    "            self._prediction_snapshots(output),\n",
    "            self._prediction_snapshots(input),\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            self._encoding_weight * decoder_loss\n",
    "            + self._phase_space_weight * psp_loss\n",
    "            + self._reconstruction_weight * reconstruction_loss\n",
    "            + self._prediction_weight * prediction_loss\n",
    "        )\n",
    "\n",
    "    @timer\n",
    "    def train_step(self, loader):\n",
    "        self.train()\n",
    "        loss_sum = 0.0\n",
    "        for i, minibatch in enumerate(loader):\n",
    "            self._optimizer.zero_grad()\n",
    "            output = self(self._dmd_training_snapshots(minibatch))\n",
    "            loss = self._compute_loss(output, minibatch)\n",
    "            loss.backward()\n",
    "            self._optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "        return loss_sum / (i + 1)\n",
    "\n",
    "    @timer\n",
    "    def eval_step(self, loader):\n",
    "        self.eval()\n",
    "        loss_sum = 0.0\n",
    "        prediction_sum = 0.0\n",
    "        for i, minibatch in enumerate(loader):\n",
    "            output = self(self._dmd_training_snapshots(minibatch))\n",
    "            loss = self._compute_loss(output, minibatch)\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            prediction_sum += mse_loss(\n",
    "                self._prediction_snapshots(output),\n",
    "                self._prediction_snapshots(minibatch),\n",
    "            ).item()\n",
    "\n",
    "        loss_avg = loss_sum / (i + 1)\n",
    "        return loss_avg, prediction_sum / (i + 1)\n",
    "\n",
    "    def save_model(self, label=\"dldmd\"):\n",
    "        temp = self._dmd\n",
    "        self._dmd = self._eval_dmd\n",
    "        torch.save(self, label + \".pl\")\n",
    "        self._dmd = temp\n",
    "\n",
    "    def load_model_for_eval(self, label=\"dldmd\"):\n",
    "        map_location = (\n",
    "            \"cpu\"\n",
    "            if self._eval_on_cpu or not torch.cuda.is_available()\n",
    "            else \"cuda\"\n",
    "        )\n",
    "        return torch.load(label + \".pl\", map_location=map_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e470d419",
   "metadata": {},
   "source": [
    "The training loop receives a blank `dldmd` instance and two 3D tensors `training_data` and `test_data` (the first dimension is dedicated to batching). Other parameters can be used as well to tune the training (number of `epochs`, `batch_size`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ccb942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dldmd(dldmd, training_data, test_data,\n",
    "                batch_size=256, epochs=1000, acceptable_loss=0, print_prediction_loss=True, \n",
    "                print_every=True, label=\"dldmd\", eval_on_cpu=True):\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        training_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    train_loss_arr = []\n",
    "    eval_loss_arr = []\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        dldmd.to(\"cuda\", dtype=training_data.dtype)\n",
    "    else:\n",
    "        dldmd.to(dtype=training_data.dtype)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        training_time, train_loss = dldmd.train_step(train_dataloader)\n",
    "        train_loss_arr.append(train_loss)\n",
    "\n",
    "        model_label = f\"{label}_e{epoch}\"\n",
    "        dldmd.save_model(model_label)\n",
    "        eval_model = dldmd.load_model_for_eval(model_label)\n",
    "\n",
    "        eval = eval_model.eval_step(test_dataloader)\n",
    "        eval_time, (eval_loss, prediction_loss) = eval\n",
    "\n",
    "        if not eval_loss_arr or min(eval_loss_arr) > eval_loss:\n",
    "            dldmd.save_model(f\"{label}_best\")\n",
    "        eval_loss_arr.append(eval_loss)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            logger.info(\n",
    "                f\"[{epoch}] loss: {eval_loss:.7f}, train_time: {training_time:.2f} ms, eval_time: {eval_time:.2f} ms\"\n",
    "            )\n",
    "            if print_prediction_loss:\n",
    "                logger.info(\n",
    "                    f\"[{epoch}] prediction loss: {prediction_loss:.7f}\"\n",
    "                )\n",
    "        else:\n",
    "            os.remove(model_label + \".pl\")\n",
    "\n",
    "        if eval_loss < acceptable_loss:\n",
    "            break\n",
    "\n",
    "    np.save(f\"{label}_train_loss.npy\", train_loss_arr)\n",
    "    np.save(f\"{label}_eval_loss.npy\", eval_loss_arr)\n",
    "    \n",
    "    return dldmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97a67f",
   "metadata": {},
   "source": [
    "We also define a very simple MLP. We're going to use an hardcoded 3-layers perceptron like [1], but there's no constraint on the number of layers. The parameters required by the MLP are the input and output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9100ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layer_size):\n",
    "        super().__init__()\n",
    "        self.layers = Sequential(\n",
    "            Linear(input_size, hidden_layer_size),\n",
    "            ReLU(),\n",
    "            Linear(hidden_layer_size, hidden_layer_size),\n",
    "            ReLU(),\n",
    "            Linear(hidden_layer_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464fb3b",
   "metadata": {},
   "source": [
    "## Data\n",
    "First of all we import a special module which we're going to use to generate data to feed DMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d04318b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).parent) + \"/src\")\n",
    "from data import data_maker_duffing_driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "511000b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_count = 100\n",
    "eval_count = 50\n",
    "\n",
    "data = data_maker_duffing_driven(\n",
    "    x_lower1=-1,\n",
    "    x_upper1=1,\n",
    "    x_lower=-1,\n",
    "    x_upper2=1,\n",
    "    n_ic=training_count + eval_count,\n",
    "    dt=0.05,\n",
    "    tf=200,\n",
    ")\n",
    "data = torch.from_numpy(data).swapaxes(-1, -2)\n",
    "training_data = data[: training_count]\n",
    "test_data = data[training_count :]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    training_data = training_data.to(device)\n",
    "    if not args.eval_on_cpu:\n",
    "        test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8ad3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 128\n",
    "immersion_size = 3\n",
    "\n",
    "encoder = MLP(data.shape[-2], immersion_size, hidden)\n",
    "decoder = MLP(immersion_size, data.shape[-2], hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbb0f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1230415297.py:22 -             __init__() ] Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 1e-09\n",
      ")\n",
      "[1230415297.py:31 -             __init__() ] DMD instance: <class 'pydmd.dmd.DMD'>\n",
      "[1230415297.py:37 -             __init__() ] DMD will predict 5 snapshots during training.\n",
      "[1230415297.py:41 -             __init__() ] ----- DLDMD children -----\n",
      "[1230415297.py:42 -             __init__() ] (MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "), MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "dmd = DMD(svd_rank=-1)\n",
    "dldmd = DLDMD(\n",
    "    encoder=encoder,\n",
    "    dmd=dmd,\n",
    "    decoder=decoder,\n",
    "    encoding_weight=1,\n",
    "    reconstruction_weight=1.e-1,\n",
    "    prediction_weight=1,\n",
    "    phase_space_weight=1.e-3,\n",
    "    n_prediction_snapshots=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9c8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[snapshots.py:40 -             __init__() ] Snapshots: torch.Size([100, 3, 3996]), snapshot shape: torch.Size([3, 3996])\n"
     ]
    }
   ],
   "source": [
    "train_dldmd(dldmd, training_data, test_data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac7a2a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 601])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = data_maker_fluid_flow_full(\n",
    "    x1_lower=-1.1,\n",
    "    x1_upper=1.1,\n",
    "    x2_lower=-1.1,\n",
    "    x2_upper=1.1,\n",
    "    x3_lower=0.0,\n",
    "    x3_upper=2,\n",
    "    n_ic=100,\n",
    "    dt=0.01,\n",
    "    tf=6,\n",
    ")\n",
    "d2 = torch.from_numpy(d2).swapaxes(-1,-2)\n",
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa52b4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[snapshots.py:40 -             __init__() ] Snapshots: torch.Size([100, 3, 596]), snapshot shape: torch.Size([3, 596])\n",
      "[snapshots.py:40 -             __init__() ] Snapshots: torch.Size([100, 3, 596]), snapshot shape: torch.Size([3, 596])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0534, dtype=torch.float64)\n",
      "tensor(0.0010, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dmd2 = DMD(svd_rank=-1).fit(d2[..., :-5], batch=True)\n",
    "dmd2.dmd_time['tend'] += 5\n",
    "rec = dmd2.reconstructed_data[..., -5:].real\n",
    "print(mse_loss(rec,d2[..., -5:]))\n",
    "\n",
    "dldmd_rec = dldmd(d2[..., :-5])[..., -5:]\n",
    "print(mse_loss(dldmd_rec,d2[..., -5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcaa5f",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] Alford-Lago, Daniel J., et al. \"Deep learning enhanced dynamic mode decomposition.\" Chaos: An Interdisciplinary Journal of Nonlinear Science 32.3 (2022): 033116."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
